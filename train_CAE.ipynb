{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aFzv1kAHpqGZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "1Cp5-De3o6lv",
    "outputId": "1cc2eef4-6e1f-496e-bf99-2d9ba87237a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:02, 3915396.89it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 57649.17it/s]                           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:01, 964483.21it/s]                             \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8192it [00:00, 21769.50it/s]            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert data to torch.FloatTensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# load the training and test datasets\n",
    "train_data = datasets.MNIST(root='data', train=True,\n",
    "                                   download=True, transform=transform)\n",
    "test_data = datasets.MNIST(root='data', train=False,\n",
    "                                  download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5bfW_B7JUFxr"
   },
   "outputs": [],
   "source": [
    "# Create training and test dataloaders\n",
    "\n",
    "# number of subprocesses to use for data loading\n",
    "num_workers = 0\n",
    "# how many samples per batch to load\n",
    "batch_size = 20\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "colab_type": "code",
    "id": "6nHAh-RZUOV-",
    "outputId": "f56e29e3-c87a-4347-ad55-01ca7fcb7390"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4918748400>"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAEvCAYAAAAtufaDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain one batch of training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "# get one image from the batch\n",
    "img = np.squeeze(images[0])\n",
    "\n",
    "fig = plt.figure(figsize = (5,5)) \n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XA46oVIi7cpm"
   },
   "source": [
    "### Convolutional Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PoJbBdPHqZgr"
   },
   "outputs": [],
   "source": [
    "# Convolutional Auto Encoder\n",
    "class CAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CAE, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Conv2d(16, 1, kernel_size=3, padding=1)  \n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 1, kernel_size=3, padding=1)\n",
    "        )      \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.encoder(x)\n",
    "        out = self.decoder(out)\n",
    "        return out\n",
    "\n",
    "# model\n",
    "model = CAE()\n",
    "\n",
    "# specify loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# specify loss function\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wU4iyzAX7jzH"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "wtUkqu9b7Ur0",
    "outputId": "1516cf8e-4571-4b45-84ae-a7ce495dc3e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 0.058238\n",
      "Epoch: 2 \tTraining Loss: 0.025352\n",
      "Epoch: 3 \tTraining Loss: 0.023325\n",
      "Epoch: 4 \tTraining Loss: 0.022295\n",
      "Epoch: 5 \tTraining Loss: 0.021086\n",
      "Epoch: 6 \tTraining Loss: 0.020351\n",
      "Epoch: 7 \tTraining Loss: 0.019868\n",
      "Epoch: 8 \tTraining Loss: 0.019503\n",
      "Epoch: 9 \tTraining Loss: 0.019277\n",
      "Epoch: 10 \tTraining Loss: 0.019060\n",
      "Epoch: 11 \tTraining Loss: 0.018875\n",
      "Epoch: 12 \tTraining Loss: 0.018738\n",
      "Epoch: 13 \tTraining Loss: 0.018603\n",
      "Epoch: 14 \tTraining Loss: 0.018489\n",
      "Epoch: 15 \tTraining Loss: 0.018387\n",
      "Epoch: 16 \tTraining Loss: 0.018299\n",
      "Epoch: 17 \tTraining Loss: 0.018227\n",
      "Epoch: 18 \tTraining Loss: 0.018168\n",
      "Epoch: 19 \tTraining Loss: 0.018084\n",
      "Epoch: 20 \tTraining Loss: 0.018009\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 20\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    # monitor training loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    for data in train_loader:\n",
    "        # _ stands in for labels, here\n",
    "        images, _ = data\n",
    "        # flatten images\n",
    "        # images = images.view(images.size(0), -1)\n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        outputs = model(images)\n",
    "        # calculate the loss\n",
    "        loss = criterion(outputs, images)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update running training loss\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "            \n",
    "    # print avg training statistics \n",
    "    train_loss = train_loss/len(train_loader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
    "        epoch, \n",
    "        train_loss\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h5Ya3KU3PDHt"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'MNIST_CAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5xH8ZZ3t7obF"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "dAyBwe1p6GXw",
    "outputId": "1cf55aa1-58c0-40cf-de7c-9b986d82dc70"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7673a2328f36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# obtain one batch of test images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataiter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#images_flatten = images.view(images.size(0), -1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_loader' is not defined"
     ]
    }
   ],
   "source": [
    "# obtain one batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "#images_flatten = images.view(images.size(0), -1)\n",
    "# get sample outputs\n",
    "output = model(images)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "# output is resized into a batch of images\n",
    "# output = output.view(batch_size, 1, 28, 28)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.detach().numpy()\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap='gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iAFsyTOlfJHQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CAE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
