{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from datasets.mnist import MNIST\n",
    "\n",
    "from models.cae_model import CAE\n",
    "from models.conv_model import CNN\n",
    "\n",
    "from train import train_ae, train_cnn\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from cem import ContrastiveExplanationMethod\n",
    "\n",
    "# set random seeds for reproducability (although the CEM is fully determininstic)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(batch_size=64)\n",
    "# dataset = FashionMNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\david\\Coding\\uva-fact-ai\\models\\conv_model.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = nn.functional.softmax(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss after step 0:2.3022148609161377 accuracy: 0.109375\n",
      "loss after step 100:2.3019509315490723 accuracy: 0.140625\n",
      "loss after step 200:2.301959991455078 accuracy: 0.0625\n",
      "loss after step 300:2.30271577835083 accuracy: 0.078125\n",
      "loss after step 400:2.3030552864074707 accuracy: 0.125\n",
      "loss after step 500:2.302427053451538 accuracy: 0.078125\n",
      "loss after step 600:2.3021762371063232 accuracy: 0.109375\n",
      "loss after step 700:2.302530288696289 accuracy: 0.078125\n",
      "loss after step 800:2.3017024993896484 accuracy: 0.109375\n",
      "loss after step 900:2.3015575408935547 accuracy: 0.15625\n",
      "done with iteration: 0/7\n",
      "loss after step 0:2.3027946949005127 accuracy: 0.09375\n",
      "loss after step 100:2.3013687133789062 accuracy: 0.125\n",
      "loss after step 200:2.3005127906799316 accuracy: 0.1875\n",
      "loss after step 300:2.3006529808044434 accuracy: 0.15625\n",
      "loss after step 400:2.301255226135254 accuracy: 0.125\n",
      "loss after step 500:2.3014659881591797 accuracy: 0.09375\n",
      "loss after step 600:2.3002796173095703 accuracy: 0.125\n",
      "loss after step 700:2.301661252975464 accuracy: 0.109375\n",
      "loss after step 800:2.299520254135132 accuracy: 0.109375\n",
      "loss after step 900:2.2969064712524414 accuracy: 0.140625\n",
      "done with iteration: 1/7\n",
      "loss after step 0:2.301257610321045 accuracy: 0.078125\n",
      "loss after step 100:2.2976064682006836 accuracy: 0.15625\n",
      "loss after step 200:2.1645073890686035 accuracy: 0.34375\n",
      "loss after step 300:2.0039727687835693 accuracy: 0.453125\n",
      "loss after step 400:1.8295164108276367 accuracy: 0.625\n",
      "loss after step 500:1.6669646501541138 accuracy: 0.796875\n",
      "loss after step 600:1.6597516536712646 accuracy: 0.796875\n",
      "loss after step 700:1.5977784395217896 accuracy: 0.859375\n",
      "loss after step 800:1.5786688327789307 accuracy: 0.890625\n",
      "loss after step 900:1.5103007555007935 accuracy: 0.953125\n",
      "done with iteration: 2/7\n",
      "loss after step 0:1.5519163608551025 accuracy: 0.921875\n",
      "loss after step 100:1.5112230777740479 accuracy: 0.953125\n",
      "loss after step 200:1.4827739000320435 accuracy: 0.984375\n",
      "loss after step 300:1.5111429691314697 accuracy: 0.953125\n",
      "loss after step 400:1.4617085456848145 accuracy: 1.0\n",
      "loss after step 500:1.5280572175979614 accuracy: 0.921875\n",
      "loss after step 600:1.4631471633911133 accuracy: 1.0\n",
      "loss after step 700:1.549193263053894 accuracy: 0.921875\n",
      "loss after step 800:1.5097922086715698 accuracy: 0.9375\n",
      "loss after step 900:1.479491949081421 accuracy: 0.984375\n",
      "done with iteration: 3/7\n",
      "loss after step 0:1.5402520895004272 accuracy: 0.921875\n",
      "loss after step 100:1.514074683189392 accuracy: 0.953125\n",
      "loss after step 200:1.543448805809021 accuracy: 0.921875\n",
      "loss after step 300:1.4945077896118164 accuracy: 0.96875\n",
      "loss after step 400:1.4882655143737793 accuracy: 0.96875\n",
      "loss after step 500:1.4636056423187256 accuracy: 1.0\n",
      "loss after step 600:1.497758150100708 accuracy: 0.96875\n",
      "loss after step 700:1.526998519897461 accuracy: 0.9375\n",
      "loss after step 800:1.4948060512542725 accuracy: 0.96875\n",
      "loss after step 900:1.5024762153625488 accuracy: 0.953125\n",
      "done with iteration: 4/7\n",
      "loss after step 0:1.4767781496047974 accuracy: 0.984375\n",
      "loss after step 100:1.4771111011505127 accuracy: 0.984375\n",
      "loss after step 200:1.5161124467849731 accuracy: 0.9375\n",
      "loss after step 300:1.494062066078186 accuracy: 0.96875\n",
      "loss after step 400:1.5144129991531372 accuracy: 0.9375\n",
      "loss after step 500:1.4620741605758667 accuracy: 1.0\n",
      "loss after step 600:1.474914312362671 accuracy: 0.984375\n",
      "loss after step 700:1.4770565032958984 accuracy: 0.984375\n",
      "loss after step 800:1.493598222732544 accuracy: 0.96875\n",
      "loss after step 900:1.5047978162765503 accuracy: 0.953125\n",
      "done with iteration: 5/7\n",
      "loss after step 0:1.473961353302002 accuracy: 0.984375\n",
      "loss after step 100:1.476325511932373 accuracy: 0.984375\n",
      "loss after step 200:1.4659610986709595 accuracy: 1.0\n",
      "loss after step 300:1.4797838926315308 accuracy: 0.96875\n",
      "loss after step 400:1.4771034717559814 accuracy: 0.984375\n",
      "loss after step 500:1.4913032054901123 accuracy: 0.96875\n",
      "loss after step 600:1.495418667793274 accuracy: 0.96875\n",
      "loss after step 700:1.4731794595718384 accuracy: 0.984375\n",
      "loss after step 800:1.4810184240341187 accuracy: 0.984375\n",
      "loss after step 900:1.4755443334579468 accuracy: 1.0\n",
      "done with iteration: 6/7\n",
      "Done training.\n"
     ]
    }
   ],
   "source": [
    "cnn = CNN(device=\"cuda:0\")\n",
    "\n",
    "train_cnn(cnn, dataset, iterations=7, lr=0.1, save_fn='mnist-cnn', device=\"cuda:0\", load_path=\"./models/saved_models/mnist-cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, _ = dataset.get_batch()\n",
    "\n",
    "output = cnn(images)\n",
    "\n",
    "images = images.numpy()\n",
    "output = output.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate the cnn by uncommenting this cell\n",
    "\n",
    "# total_acc = 0\n",
    "# total_batches = 0\n",
    "# for step, (batch_inputs, batch_targets) in enumerate(dataset.test_loader):\n",
    "    \n",
    "#     predictions = cnn(batch_inputs)\n",
    "#     acc = (predictions.argmax(1).cpu().numpy() == batch_targets.cpu().numpy()).sum()/(predictions.shape[0] )\n",
    "#     total_batches += 1\n",
    "#     total_acc += acc\n",
    "    \n",
    "# print(\"acc: {}\".format(total_acc / total_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section trains the autoencoder which will be used as regularizer for the data space which the perturbations are found in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load autoencoder\n",
    "cae = CAE(device=\"cpu\")\n",
    "\n",
    "train_ae(cae, dataset, iterations=10, save_fn=\"mnist-cae\", device=\"cpu\", load_path=\"models/saved_models/mnist-cae-no-rs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain one batch of test images\n",
    "images, _ = dataset.get_batch()\n",
    "\n",
    "images += 0.5\n",
    "\n",
    "#images_flatten = images.view(images.size(0), -1)\n",
    "# get sample outputs\n",
    "output = cae(images)\n",
    "# prep images for display\n",
    "images = images.numpy()\n",
    "\n",
    "# output is resized into a batch of images\n",
    "# output = output.view(batch_size, 1, 28, 28)\n",
    "# use detach when it's an output that requires_grad\n",
    "output = output.detach().numpy()\n",
    "\n",
    "# plot the first ten input images and then reconstructed images\n",
    "fig, axes = plt.subplots(nrows=2, ncols=4, sharex=True, sharey=True, figsize=(25,4))\n",
    "\n",
    "# input images on top row, reconstructions on bottom\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img))\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Explanation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal: kappa 30, gamma 1.0, beta 0.1, lr 0.01\n",
    "\n",
    "kappa = 10\n",
    "gamma = 1.0\n",
    "beta = 0.1\n",
    "lr = 0.01\n",
    "device = \"cpu\"\n",
    "\n",
    "CEM = ContrastiveExplanationMethod(\n",
    "    cnn,\n",
    "    cae,\n",
    "    iterations=1000,\n",
    "    n_searches=9,\n",
    "    kappa=kappa,\n",
    "    gamma=gamma,\n",
    "    beta=beta,\n",
    "    learning_rate=lr,\n",
    "    c_init=10.0,\n",
    "    device=device,\n",
    "    verbal=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_imgs():\n",
    "    # save the created images\n",
    "    dirname = \"saved_perturbations/mode-{}-kappa-{}-gamma-{}-beta-{}-lr-{}\".format(mode, kappa, gamma, beta, lr)\n",
    "    os.makedirs(dirname, exist_ok=True)\n",
    "    \n",
    "    fname_orig = dirname + \"/{}-cb-{}-ca-{}-orig.png\".format(int(time.time()), before, after)\n",
    "    fname_pert = dirname + \"/{}-before-{}-after-{}-pert.png\".format(int(time.time()), before, after)\n",
    "    fname_combined = dirname + \"/{}-before-{}-after-{}-pn.png\".format(int(time.time()), before, after)\n",
    "    fname_combined_pp = dirname + \"/{}-before-{}-after-{}-pp.png\".format(int(time.time()), before, after)\n",
    "    \n",
    "    plt.imsave(fname_orig, image.squeeze(), cmap=\"gray\")\n",
    "    plt.imsave(fname_pert, best_delta.view(28,28) - image.squeeze(), cmap=\"gray\")\n",
    "    plt.imsave(fname_combined, best_delta.view(28,28), cmap=\"gray\")\n",
    "    plt.imsave(fname_combined_pp, image.squeeze() - best_delta.view(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    # obtain one sample\n",
    "    image = dataset.get_sample_by_class(class_label=i, show_image=False).to(device)\n",
    "\n",
    "    print(\"IMAGE FROM CLASS: {}\".format(i))\n",
    "    before = np.argmax(cnn(image.squeeze(-1)).detach().cpu()).item()\n",
    "    \n",
    "    for mode in [\"PP\", \"PN\"]:\n",
    "        print(\"mode: {}\".format(mode))\n",
    "        best_delta = CEM.explain(image, mode=mode)\n",
    "        \n",
    "        if mode == \"PP\":\n",
    "            after = np.argmax(cnn(image.squeeze(-1) - best_delta.view(1,28,28)).detach().cpu()).item()\n",
    "        else:\n",
    "            after = np.argmax(cnn(best_delta.view(1,28,28)).detach().cpu()).item()\n",
    "        \n",
    "        save_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print original image\n",
    "plt.imshow(image.view(28,28), cmap=\"gray\")\n",
    "plt.show()\n",
    "\n",
    "# classification before\n",
    "before = np.argmax(cnn(image.squeeze(-1)).detach()).item()\n",
    "print(\"classification before perturbation: {}\".format(before))\n",
    "\n",
    "if mode == \"PP\":\n",
    "    plt.imshow(image.squeeze() - CEM.best_delta.view(28,28), cmap=\"gray\")\n",
    "    plt.show()\n",
    "    after = np.argmax(cnn(image.squeeze(-1) - CEM.best_delta.view(1,28,28)).detach()).item()\n",
    "    print(\"classification of delta: {}\".format(after))\n",
    "else:\n",
    "    plt.imshow(CEM.best_delta.view(28,28),  cmap=\"gray\")\n",
    "    plt.show()\n",
    "    after = np.argmax(cnn(CEM.best_delta.view(1,28,28)).detach()).item()\n",
    "    print(\"classification after perturbation: {}\".format(after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(float(\"inf\") > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.conv_model_copy import CNN as CNN1\n",
    "\n",
    "image, _ = dataset.get_sample()\n",
    "\n",
    "cnn1 = CNN1()\n",
    "\n",
    "cnn1(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
