{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import os\n",
    "import torch\n",
    "\n",
    "from datasets.mnist import MNIST\n",
    "\n",
    "from models.cae_model import CAE\n",
    "from models.conv_model import CNN\n",
    "\n",
    "from train import train_ae, train_cnn\n",
    "\n",
    "from cem import ContrastiveExplanationMethod as ContrastiveExplanationMethod\n",
    "\n",
    "# set random seeds for reproducability (although the CEM is fully determininstic)\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the following variables to either include or skip over optional\n",
    "# evaluation metrics for the CNN and autoencoder\n",
    "EVALUATE_CNN = False\n",
    "EVALUATE_AUTOENCODER = False\n",
    "\n",
    "# Change the following variable to have the script create full set of images\n",
    "# for every class, used in the paper.\n",
    "EVALUATE_CEM = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of the CEM on the MNIST dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the classifier\n",
    "\n",
    "This section trains the classifier for which the pertinent positives and negatives will be constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(device=\"cpu\")\n",
    "\n",
    "train_cnn(cnn, dataset, iterations=20, lr=0.01, save_fn='mnist-cnn', device=\"cpu\", load_path=\"models/saved_models/mnist-cnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\david\\Coding\\uva-fact-ai\\models\\conv_model.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  out = nn.functional.softmax(out)\n"
     ]
    }
   ],
   "source": [
    "images, _ = dataset.get_batch()\n",
    "\n",
    "output = cnn(images)\n",
    "\n",
    "images = images.numpy()\n",
    "output = output.detach().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell evaluates the performance of the CNN on the specified test set.\n",
    "if EVALUATE_CNN:\n",
    "\n",
    "    total_acc = 0\n",
    "    total_batches = 0\n",
    "    for step, (batch_inputs, batch_targets) in enumerate(dataset.test_loader):\n",
    "\n",
    "        predictions = cnn(batch_inputs)\n",
    "        acc = (predictions.argmax(1).cpu().numpy() == batch_targets.cpu().numpy()).sum()/(predictions.shape[0] )\n",
    "        total_batches += 1\n",
    "        total_acc += acc\n",
    "\n",
    "    print(\"acc: {}\".format(total_acc / total_batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section trains the autoencoder which will be used as regularizer for the data space which the perturbations are found in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load autoencoder\n",
    "cae = CAE(device=\"cpu\")\n",
    "\n",
    "train_ae(cae, dataset, iterations=10, save_fn=\"mnist-cae\", device=\"cpu\", load_path=\"models/saved_models/mnist-cae-no-rs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell evaluates the performance of the autoencoder by visualising a batch of \n",
    "# in- and corresponding output images.\n",
    "if EVALUATE_AUTOENCODER:\n",
    "    images, _ = dataset.get_batch()\n",
    "    images += 0.5 # rescale images\n",
    "\n",
    "    # get sample outputs\n",
    "    output = cae(images)\n",
    "    # prep images for display\n",
    "    images = images.numpy()\n",
    "    output = output.detach().numpy()\n",
    "\n",
    "    # plot the first ten input images and then reconstructed images\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=4, sharex=True, sharey=True, figsize=(12,4))\n",
    "\n",
    "    # input images on top row, reconstructions on bottom\n",
    "    for images, row in zip([images, output], axes):\n",
    "        for img, ax in zip(images, row):\n",
    "            ax.imshow(np.squeeze(img))\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Explanation Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal: kappa 30, gamma 1.0, beta 0.1, c 0.1, lr 0.01\n",
    "\n",
    "kappa = 30\n",
    "gamma = 1.0\n",
    "beta = 0.1\n",
    "c = 0.1\n",
    "lr = 0.01\n",
    "\n",
    "CEM = ContrastiveExplanationMethod(\n",
    "    cnn,\n",
    "    cae,\n",
    "    iterations=1000,\n",
    "    n_searches=9,\n",
    "    kappa=kappa,\n",
    "    gamma=gamma,\n",
    "    beta=beta,\n",
    "    learning_rate=lr,\n",
    "    c_init=10.0,\n",
    "    c_converge=c,\n",
    "    verbal=True,\n",
    "    print_every=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_save_pertinents(image):\n",
    "    \"\"\"\n",
    "    Finds pertinent positives and negatives for a given image,\n",
    "    creates and saves visualisations of the original image, the pertinents and\n",
    "    the image after being perturbed by the pertinent.\n",
    "    \n",
    "    image\n",
    "        The image to find pertinent positives and negatives for.\n",
    "    \"\"\"\n",
    "    before = np.argmax(cnn(image.squeeze(-1)).detach()).item()\n",
    "    \n",
    "    print(\"FINDING PERTINENTS FOR IMAGE OF CLASS: {}\\n\\n\".format(before))\n",
    "    \n",
    "    for mode in [\"PP\", \"PN\"]:\n",
    "        \n",
    "        CEM.fista(image, mode=mode)\n",
    "        \n",
    "        if mode == \"PP\":\n",
    "            after = np.argmax(cnn(image.squeeze(-1) - CEM.best_delta.view(1,28,28)).detach()).item()\n",
    "        else:\n",
    "            after = np.argmax(cnn(CEM.best_delta.view(1,28,28)).detach()).item()\n",
    "            \n",
    "        dirname = \"saved_perturbations/mode-{}-kappa-{}-gamma-{}-beta-{}-lr-{}\".format(mode, kappa, gamma, beta, lr)\n",
    "        os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "        fname_orig = dirname + \"/{}-orig.png\".format(before)\n",
    "        fname_pert = dirname + \"/before-{}-after-{}-pert.png\".format(before, after)\n",
    "        fname_combined_pn = dirname + \"/before-{}-after-{}-pn.png\".format(before, after)\n",
    "        fname_combined_pp = dirname + \"/before-{}-after-{}-pp.png\".format(before, after)\n",
    "\n",
    "        if mode == \"PP\":\n",
    "            plt.imsave(fname_orig, image.squeeze(), cmap=\"gray\")\n",
    "            plt.imsave(fname_pert, CEM.best_delta.view(28,28) - image.squeeze(), cmap=\"gray\")\n",
    "            plt.imsave(fname_combined_pp, image.squeeze() - CEM.best_delta.view(28,28), cmap=\"gray\")\n",
    "        else:\n",
    "            plt.imsave(fname_orig, image.squeeze(), cmap=\"gray\")\n",
    "            plt.imsave(fname_pert, CEM.best_delta.view(28,28) - image.squeeze(), cmap=\"gray\")\n",
    "            plt.imsave(fname_combined, CEM.best_delta.view(28,28), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This cell samples an image from every class and creates its pertinent positives and\n",
    "# negatives. Running this cell creates the images used in the paper.\n",
    "if EVALUATE_CEM:\n",
    "    for i in range(10):\n",
    "\n",
    "        # obtain one sample from each class\n",
    "        image = dataset.get_sample_by_class(class_label=i, show_image=False)\n",
    "        find_save_pertinents(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: 0 iteration: 500 c: 10.0 loss: 296.24 found optimum: False\n",
      "search: 0 iteration: 1000 c: 10.0 loss: 343.90 found optimum: False\n",
      "new best delta found with loss: 123.26921081542969\n",
      "new best delta found with loss: 111.13017272949219\n",
      "new best delta found with loss: 105.88893127441406\n",
      "new best delta found with loss: 103.71693420410156\n",
      "new best delta found with loss: 102.16913604736328\n",
      "new best delta found with loss: 96.91859436035156\n",
      "new best delta found with loss: 96.45509338378906\n",
      "new best delta found with loss: 91.85382080078125\n",
      "search: 1 iteration: 500 c: 100.0 loss: 101.34 found optimum: True\n",
      "new best delta found with loss: 89.89668273925781\n",
      "new best delta found with loss: 89.27206420898438\n",
      "new best delta found with loss: 89.16683959960938\n",
      "new best delta found with loss: 86.59176635742188\n",
      "new best delta found with loss: 85.93203735351562\n",
      "new best delta found with loss: 85.35089111328125\n",
      "new best delta found with loss: 83.03962707519531\n",
      "search: 1 iteration: 1000 c: 100.0 loss: 2300.55 found optimum: True\n",
      "new best delta found with loss: 82.81639862060547\n",
      "new best delta found with loss: 80.51300048828125\n",
      "search: 2 iteration: 500 c: 50.05 loss: 119.72 found optimum: True\n",
      "new best delta found with loss: 79.46095275878906\n",
      "new best delta found with loss: 78.79911804199219\n",
      "new best delta found with loss: 76.9212417602539\n",
      "new best delta found with loss: 76.70838928222656\n",
      "search: 2 iteration: 1000 c: 50.05 loss: 1551.58 found optimum: True\n",
      "search: 3 iteration: 500 c: 25.075 loss: 222.39 found optimum: True\n",
      "new best delta found with loss: 74.53484344482422\n",
      "search: 3 iteration: 1000 c: 25.075 loss: 798.47 found optimum: True\n",
      "search: 4 iteration: 500 c: 12.5875 loss: 221.15 found optimum: False\n",
      "search: 4 iteration: 1000 c: 12.5875 loss: 421.93 found optimum: False\n",
      "search: 5 iteration: 500 c: 125.875 loss: 533.24 found optimum: True\n",
      "search: 5 iteration: 1000 c: 125.875 loss: 1906.23 found optimum: True\n",
      "search: 6 iteration: 500 c: 62.9875 loss: 255.89 found optimum: True\n",
      "search: 6 iteration: 1000 c: 62.9875 loss: 1941.68 found optimum: True\n",
      "search: 7 iteration: 500 c: 31.54375 loss: 112.57 found optimum: True\n",
      "search: 7 iteration: 1000 c: 31.54375 loss: 993.53 found optimum: True\n",
      "search: 8 iteration: 500 c: 15.821875 loss: 202.23 found optimum: True\n",
      "search: 8 iteration: 1000 c: 15.821875 loss: 519.46 found optimum: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-03c9de9b0c31>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"PP\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbest_delta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pertinent positive, classified as: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mafter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\david\\miniconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2699\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2700\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[1;32m-> 2701\u001b[1;33m         None else {}), **kwargs)\n\u001b[0m\u001b[0;32m   2702\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2703\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\david\\miniconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1808\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1810\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32md:\\david\\miniconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[0;32m   5493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5494\u001b[1;33m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5496\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\david\\miniconda3\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mset_data\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m    644\u001b[0m         if not (self._A.ndim == 2\n\u001b[0;32m    645\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[1;32m--> 646\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    647\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obtain one sample\n",
    "image, _ = dataset.get_sample(show_image=False)\n",
    "before = np.argmax(cnn(image.squeeze(-1)).detach()).item()\n",
    "\n",
    "mode = \"PP\"\n",
    "best_delta = CEM.explain(image, mode=mode)\n",
    "\n",
    "if mode == \"PP\":\n",
    "    after = np.argmax(cnn(image.squeeze(-1) - best_delta.view(1,28,28)).detach()).item()\n",
    "else:\n",
    "    after = np.argmax(cnn(best_delta.view(1,28,28)).detach()).item()\n",
    "        \n",
    "plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "plt.title(\"original image, classified as: {}\".format(before))\n",
    "plt.show()\n",
    "\n",
    "if mode == \"PP\":\n",
    "    plt.imshow(image.squeeze() - best_delta.view(28, 28))\n",
    "    plt.title(\"pertinent positive, classified as: {}\".format(after))\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.imshow(best_delta.squeeze())\n",
    "    plt.title(\"image with pertinent negative, classified as: {}\".format(after))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance of the CEM on the FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FashionMNIST(batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train or load autoencoder\n",
    "cae = CAE(device=\"cpu\")\n",
    "\n",
    "train_ae(cae, dataset, iterations=10, save_fn=\"fashion-mnist-cae\", device=\"cpu\", load_path=\"models/saved_models/fashion-mnist-cae.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
